{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4jnTbvGsXOm",
        "outputId": "0e938734-853a-42e2-8099-407c4842dc3d"
      },
      "source": [
        "# CNN : Convolutional Neural Network\n",
        "# 2차원 합성곱\n",
        "# 오른쪽으로 한칸 이동, 아래로 한칸이동\n",
        "# 4*4, 3*3, 2*2\n",
        "\n",
        "# 3,1,0,7           w1,w2,w3               3*w1 + 1*w2, 0*w3 + 6*w4 + 4*w5 + 8*w6 + 4*w7 + 5 *w8 + 1*w9 + b => 1개의 출력 \n",
        "# 6,4,8,2           w4,w5,w6\n",
        "# 4,5,1,1           w7,w8,w9\n",
        "# 3,2,5,8\n",
        "\n",
        "\n",
        "# 인공 신경망은 처음에 가중치 w1~w9와 절편 b를 랜덤하게 초기화한 다음 epochs를 반복하면서 경사 하강법 알고리즘을\n",
        "# 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아갑니다. 이것이 모델 훈련입니다.\n",
        "\n",
        "# CNN은 입력데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다.\n",
        "\n",
        "# CNN 계산을 통해 얻은 출력을 특별히 특성맵(feature map)이라고 한다.\n",
        "# kernel_size는 하이퍼파라미터이다, 보통 (3,3) or (5,5)를 많이 사용함.\n",
        "\n",
        "#from tensorflow import keras\n",
        "#keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')\n",
        "\n",
        "# padding : filter의 슬라이딩의 숫자를 늘려주는 것, 입력 배열의 주위를 가상의 원소로 채우는 것\n",
        "# 픽셀마다 기여하는 정보가 틀림. 주변 픽셀의 정보를 잘 감지하기 위해 추가함\n",
        "\n",
        "#keras.layers.Conv2D(10, kernel_size(3,3), activation='relu', padding='same') # padding='valid' \n",
        "\n",
        "# 스트라이드 : 이동하는 크기를 스트라이드라고 함\n",
        "#keras.layers.Conv2D(10, kernel_size(3,3), activation='relu', padding='same', strides=1) \n",
        "\n",
        "# pooling, 가중치는 없다, 겹치지 않는다\n",
        "# 평균풀링\n",
        "# 최대풀링\n",
        "\n",
        "#keras.layers.MaxPooling2D(2)\n",
        "\n",
        "\n",
        "# 6*6 => 3*3의 3개의 필터 => (4,4) 특성맵 3개 => (4,4,3) 특성맵 => 2*2 최대풀링 => (2,2,3) 특성맵 => 12, 크기입력\n",
        "\n",
        "# 3차원(너비*높이*깊이(채널)) 합성곱\n",
        "# 입력의 깊이와 커널의 깊이는 같다.\n",
        "\n",
        "#(4,4,3)크기 입력과 (3,3,3)크기 커널의 합성곱\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) =\\\n",
        " keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(train_input.shape, train_target.shape)\n",
        "\n",
        "\n",
        "#keras model create\n",
        "from sklearn.model_selection import train_test_split\n",
        "(train_input, train_target), (test_input, test_target) =\\\n",
        " keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "#채널 차원을 늘림\n",
        "train_scaled = train_input.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "#keras model create\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1)))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "keras.utils.plot_model(model, show_shapes=True, to_file='cnn-architecture.png', dpi=300)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5')\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_scaled, train_target, epochs=20,\n",
        "                    validation_data=(val_scaled, val_target),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n",
        "\n",
        "model.evaluate(val_scaled, val_target)\n",
        "\n",
        "plt.imshow(val_scaled[0].reshape(28,28), cmap='gray_r')\n",
        "plt.show()\n",
        "\n",
        "preds = model.predict(val_scaled[0:1])\n",
        "print(preds)\n",
        "\n",
        "plt.bar(range(1,11), preds[0])\n",
        "plt.xlabel('class')\n",
        "plt.ylabel('prob.')\n",
        "plt.show()\n",
        "\n",
        "classes = ['티셔츠', '바지', '스웨터', '드레스', '코트', '샌달', '셔츠', '스니커즈', '가방', '앵클 부츠']\n",
        "test_scaled = test_input.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "model.evaluate(test_scaled, test_target)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               313700    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 333,526\n",
            "Trainable params: 333,526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1034/1500 [===================>..........] - ETA: 17s - loss: 0.7670 - accuracy: 0.7297"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LVaBJz06jRv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS9sBZD36jmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}