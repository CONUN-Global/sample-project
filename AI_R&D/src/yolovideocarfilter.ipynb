{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolovideocarfilter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgR6Cb3uAbeO"
      },
      "source": [
        "# 1. darknet clone\n",
        "runntime => GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Xrb5PIAD_c"
      },
      "source": [
        "#clone darknet repo\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HphO7PeQBC1F"
      },
      "source": [
        "!ls -al darknet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCDeRRhkBZns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06d1f14-9eb2-43d2-f4ba-679241a6a403"
      },
      "source": [
        "%cd darknet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'darknet'\n",
            "/content/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28emisrwBjsl"
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFzkur6KBmI2"
      },
      "source": [
        "#change makefile to have OPENCV, GPU, CUDNN enabled\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzTIWMmTCJEr"
      },
      "source": [
        "#verify CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBH5gfNbDPQL"
      },
      "source": [
        "#compile Darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9HE_U7GD5By"
      },
      "source": [
        "#get yolov3 pretrained coco dataset weights\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CENH0NXaE7jr"
      },
      "source": [
        "#run darknet detection\n",
        "!./darknet detect cfg/yolov3.cfg yolov3.weights data/giraffe.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857y_q0BFkqx"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import IPython\n",
        "import time\n",
        "import math\n",
        "\n",
        "result = cv2.imread('predictions.jpg')\n",
        "cv2_imshow(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lws9gLDrMyfp"
      },
      "source": [
        "#2. OpenCV YOLO video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj46OulOM2r5"
      },
      "source": [
        "min_confidence = 0.5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ake0dMvSNA2Z"
      },
      "source": [
        "weight_file = 'yolov3.weights'\n",
        "cfg_file = 'cfg/yolov3.cfg'\n",
        "name_file = 'data/coco.names'\n",
        "\n",
        "#https://bdd-data.berkeley.edu/ 에서 dataset download\n",
        "#http://dl.yf.io/bdd100k/video_parts/bdd100k_videos_test_00.zip의 첫번째 video file\n",
        "file_name = 'cabc30fc-e7726578.mp4'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDiiFjHLNXgZ"
      },
      "source": [
        "!ls -al cfg/yolov3.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO02va2xNfjJ"
      },
      "source": [
        "#load yolo\n",
        "net = cv2.dnn.readNet(weight_file, cfg_file)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG_-JmrINnDJ",
        "outputId": "e636e6c0-85da-4358-de37-b1dfeba64649"
      },
      "source": [
        "classes = []\n",
        "with open(name_file, 'r') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "print(classes)\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0]-1] for i in net.getUnconnectedOutLayers()]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2u-uooWOb8B"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MVzcsdXXOaP"
      },
      "source": [
        "frame_count = 0\n",
        "#initialize the video writer\n",
        "writer = None\n",
        "output_name = 'output_video.avi'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qDHu1mPXikt"
      },
      "source": [
        "def writeFrame(img):\n",
        "  #use global variable, writer\n",
        "  global writer, frame_count\n",
        "  frame_count += 1\n",
        "  print(\"Frame: \", frame_count)\n",
        "  height, width  = img.shape[:2]\n",
        "  if writer is None and output_name is not None:\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "    writer = cv2.VideoWriter(output_name, fourcc, 24, (width, height), True)\n",
        "  if writer is not None:\n",
        "    writer.write(img)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNN2einBO8vI"
      },
      "source": [
        "def detectAndDisplay(frame):\n",
        "  global frame_count\n",
        "  frame_count += 1\n",
        "  start_time = time.time()\n",
        "\n",
        "  IPython.display.clear_output(wait=True)\n",
        "  height, width, channels = frame.shape\n",
        "\n",
        "  blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0,0,0), True, crop=False)\n",
        "\n",
        "  net.setInput(blob)\n",
        "  outs = net.forward(output_layers)\n",
        "  \n",
        "  class_ids = []\n",
        "  confidences = []\n",
        "  boxes = []\n",
        "  \n",
        "  for out in outs:\n",
        "    for detection in out:\n",
        "      scores = detection[5:]\n",
        "      class_id = np.argmax(scores)\n",
        "      confidence = scores[class_id]\n",
        "\n",
        "      #filter only car\n",
        "      if (confidence > min_confidence) and class_id == 2:\n",
        "        #object detected\n",
        "        center_x = int(detection[0]*width)\n",
        "        center_y = int(detection[1]*height)\n",
        "        w = int(detection[2]*width)\n",
        "        h = int(detection[3]*height)\n",
        "\n",
        "        #rectangle coordinates\n",
        "        x = int(center_x - w / 2)\n",
        "        y = int(center_y - h / 2)\n",
        "\n",
        "        boxes.append([x, y, w, h])\n",
        "        confidences.append(float(confidence))\n",
        "        class_ids.append(class_id)\n",
        "\n",
        "  #Region of interest\n",
        "  mask = np.zeros((height, width), dtype='uint8')\n",
        "\n",
        "  poly_top = int(0.65*height)\n",
        "  poly_bottom = int(0.85 * height)  \n",
        "  poly_left = int(0.47 * width)\n",
        "  poly_right = int(0.53 * width)\n",
        "\n",
        "  roi_left = int(0.3 * width)\n",
        "  roi_right = int(0.6 * width)\n",
        "\n",
        "  poly_margin = 50\n",
        "  polygons = np.array([[(0+poly_margin,poly_bottom), (poly_left, poly_top), (poly_right, poly_top), (width-poly_margin, poly_bottom)]])\n",
        "  cv2.fillPoly(mask, polygons, 255)\n",
        "\n",
        "  indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence, 0.4)\n",
        "  font = cv2.FONT_HERSHEY_COMPLEX\n",
        "  margin = 5\n",
        "  for i in range(len(boxes)):\n",
        "    if i in indexes:\n",
        "      x, y, w, h = boxes[i]\n",
        " \n",
        "      #bitwise operation between box and mask\n",
        "      box = np.array([[(x-margin, y+h+margin), (x-margin,y-margin), (x+w+margin,y),(x+w+margin, y+h+margin)]])\n",
        "      cv2.fillPoly(mask, box, 0)\n",
        "      \n",
        "      #eliminate small object( < 50 )\n",
        "      if ( w > 50 ) and ( x > roi_left and x < roi_right):\n",
        "        label = str(classes[class_ids[i]])\n",
        "        print(i, label)\n",
        "        color = (0, 255, 0)\n",
        "        cv2.rectangle(frame, (x,y), (x+w, y+h), color, 2)\n",
        "        cv2.putText(frame, label, (x, y+30), font, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "  \n",
        "  #lane detection\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  #gaussianblur for refucing noise\n",
        "  blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "\n",
        "  canny = cv2.Canny(blur, 40, 130)\n",
        "\n",
        "  #bitwise operation between poly and mask\n",
        "  masked = cv2.bitwise_and(canny, mask)\n",
        "\n",
        "  #lane detection\n",
        "  lines = cv2.HoughLinesP(masked, 2, np.pi / 180, 20, np.array([]), 20, 10)\n",
        "\n",
        "  if lines is not None:\n",
        "    for line in lines:\n",
        "      for x1, y1, x2, y2 in line:\n",
        "        cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 255), 5)\n",
        "\n",
        "  frame_time = time.time() - start_time\n",
        "  print(\"Frame {} time {}\".format(frame_count, frame_time))\n",
        "  cv2_imshow(frame)\n",
        "  writeFrame(frame)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C6T51FRO_RA"
      },
      "source": [
        "cap = cv2.VideoCapture(file_name)\n",
        "if not cap.isOpened:\n",
        "  print('opening video capture')\n",
        "  exit(0)\n",
        "\n",
        "while True:\n",
        "  re, frame = cap.read()\n",
        "  if frame is None:\n",
        "    print('captured frame - break')\n",
        "    break\n",
        "  detectAndDisplay(frame)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}